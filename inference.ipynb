{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import mod\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from typing import Dict, Tuple\n",
    "import torchio as tio\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import data\n",
    "from data.datasets import MedicalDecathlonDataset, BrainTumourDataset\n",
    "from utils.assertions import ensure\n",
    "\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import nibabel as nib\n",
    "from utils.metrics import dice_coefficient, dice_coefficient_classes\n",
    "from utils.utils import setup_seed\n",
    "from hydra.utils import instantiate\n",
    "import os\n",
    "from data.datasets import MedicalDecathlonDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def model_params(model_dir_str):\n",
    "\tmodel_dir = Path(model_dir_str)\n",
    "\tif not model_dir.is_dir():\n",
    "\t\traise FileNotFoundError(f\"Model directory not found: {model_dir}\")\n",
    "\t\n",
    "\tmodel_path = f\"{model_dir}/best_model.pth\"\n",
    "\tcfg = OmegaConf.load(f\"{model_dir}/config.yaml\")\n",
    "\n",
    "\tif not isinstance(cfg, DictConfig):\n",
    "\t\traise TypeError(\"cfg must be a DictConfig.\")\n",
    "\n",
    "\treturn model_path, cfg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasimulation \n",
    "### DataSimulation -- Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/Task04_Hippocampus_Scaled/imagesTs/scale0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m img_dir \u001b[38;5;241m=\u001b[39m base_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagesTs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscale\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m lbl_dir \u001b[38;5;241m=\u001b[39m base_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabelsTs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscale\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 14\u001b[0m img_dir_sort \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m lbl_dir_sort \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(lbl_dir))\n\u001b[1;32m     16\u001b[0m dataset \u001b[38;5;241m=\u001b[39m MedicalDecathlonDataset(cfg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, img_dir_sort, lbl_dir_sort, \u001b[38;5;28mstr\u001b[39m(img_dir), \u001b[38;5;28mstr\u001b[39m(lbl_dir))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/Task04_Hippocampus_Scaled/imagesTs/scale0'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# model_dir_str = \"trained_models/ms-unet3d/Task04_Hippocampus/2025-05-05_12-17-39\"\n",
    "model_dir_str = \"trained_models/ms-unet3d/Task04_Hippocampus/2025-05-07_15-16-30\"\n",
    "\n",
    "model_path, cfg = model_params(model_dir_str)\n",
    "scales = [0, 1, 2, 3, 4]\n",
    "\n",
    "base_dir = Path(cfg.dataset.base_path)\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for scale in scales:\n",
    "\timg_dir = base_dir / \"imagesTs\" / f\"scale{scale}\"\n",
    "\tlbl_dir = base_dir / \"labelsTs\" / f\"scale{scale}\"\n",
    "\timg_dir_sort = sorted(os.listdir(img_dir))\n",
    "\tlbl_dir_sort = sorted(os.listdir(lbl_dir))\n",
    "\tdataset = MedicalDecathlonDataset(cfg, \"test\", img_dir_sort, lbl_dir_sort, str(img_dir), str(lbl_dir))\n",
    "\tdatasets[scale] = dataset\n",
    "\n",
    "\n",
    "setup_seed(cfg.seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = instantiate(cfg.architecture.path, cfg)\n",
    "\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model_state_dict = checkpoint[\"model_state_dict\"]\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "results_per_scale = {scale: [] for scale in scales}\n",
    "# print(\"******************* TEST 1 *******************\")\n",
    "# print(\"THIS ASSUMES DATASET IS TARGET_SHAPE I THINK? I REMOVED THE TARGET SHAPE PADDING TO TEST BELOW TEST 2...\")\n",
    "# for image, label in datasets[0]:\n",
    "# \timage_tensor = image.unsqueeze(0).to(device)\n",
    "# \tsegs, _ = model(image_tensor)\n",
    "# \tfor i in range(len(segs)):\n",
    "# \t\tprint(f\"[Scale {i} | Image Shape {segs[i].shape}\")\n",
    "# \t\tpreds = segs[i]\n",
    "# \t\tpred = torch.argmax(preds, dim=1).squeeze(0)\n",
    "# \t\tlabel = label.squeeze(0).to(device)\n",
    "# \t\tdownsampled_label = F.interpolate(\n",
    "# \t\t\t\t\tlabel.unsqueeze(0).unsqueeze(0).float(),\n",
    "# \t\t\t\t\tsize=pred.shape,\n",
    "# \t\t\t\t\tmode=\"nearest\",\n",
    "# \t\t\t\t).squeeze(0).squeeze(0)\n",
    "# \t\td = dice_coefficient(\n",
    "# \t\t\tpred, downsampled_label, num_classes=cfg.dataset.num_classes, ignore_index=0\n",
    "# \t\t)\n",
    "# \t\tresults_per_scale[i] += [d.item()]\n",
    "  \n",
    "  \n",
    "# print(\"Results per scale:\")\n",
    "# for scale, results in results_per_scale.items():\n",
    "# \tprint(f\"Scale {scale}: {results}\")\n",
    "# \tmean_dice = np.mean(results)\n",
    "# \tstd_dice = np.std(results)\n",
    "# \tprint(f\"Mean Dice: {mean_dice:.4f}, Std Dice: {std_dice:.4f}\")\n",
    "\n",
    "\n",
    "results_per_scale = {scale: [] for scale in scales}\n",
    "print(\"******************* TEST 2 *******************\")\n",
    "for scale in scales:\n",
    "\twith torch.no_grad():\n",
    "\t\tfor image, label in datasets[scale]:\n",
    "\t\t\timage_tensor = image.unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "\t\t\t# print(image.shape)\n",
    "\t\t\t# print(f\"[Scale {scale} | Image Shape {image_tensor.shape}\")\n",
    "\t\t\t# print(f\"[Scale {scale} | Label Shape nig {label.shape}\")\n",
    "\n",
    "\t\t\toutput = model.run_inference(image_tensor)\n",
    "   \n",
    "\t\t\tlabel = label.squeeze(0).to(device)\n",
    "\t\t\tpred = torch.argmax(output, dim=1)\n",
    "\t\t\td = dice_coefficient(\n",
    "\t\t\t\tpred, label, num_classes=cfg.dataset.num_classes, ignore_index=0\n",
    "\t\t\t)\n",
    "\t\t\tresults_per_scale[scale] += [d.item()]\n",
    "\n",
    "\n",
    "print(\"Results per scale:\")\n",
    "for scale, results in results_per_scale.items():\n",
    "    print(f\"Scale {scale}: {results}\")\n",
    "    mean_dice = np.mean(results)\n",
    "    std_dice = np.std(results)\n",
    "    print(f\"Mean Dice: {mean_dice:.4f}, Std Dice: {std_dice:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSimulation -- BackBone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (test phase): 484\n",
      "Image shape: torch.Size([1, 4, 155, 240, 240])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 18 but got size 19 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Run inference\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 77\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# If model returns deep supervision outputs, take the final prediction\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n",
      "File \u001b[0;32m~/.conda/envs/bp/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/bp/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/medsegnet/models/MultiScale.py:27\u001b[0m, in \u001b[0;36mMSUNet3D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 27\u001b[0m     full_seg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# ===== Multiscale inputs (during training) =====\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     ms_outputs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Desktop/medsegnet/models/Backbone.py:101\u001b[0m, in \u001b[0;36mBackboneUNet3D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     99\u001b[0m out \u001b[38;5;241m=\u001b[39m up_conv(out)\n\u001b[1;32m    100\u001b[0m skip \u001b[38;5;241m=\u001b[39m enc_feats\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m--> 101\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m out \u001b[38;5;241m=\u001b[39m dec(out)\n\u001b[1;32m    103\u001b[0m out \u001b[38;5;241m=\u001b[39m drop(out)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 18 but got size 19 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "from ast import mod\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "import data\n",
    "from data.datasets import MedicalDecathlonDataset, BrainTumourDataset\n",
    "from utils.assertions import ensure\n",
    "\n",
    "\n",
    "# ------ Change only this for test of a trained model ------\n",
    "# model_dir_str = \"trained_models/ms-unet3d/Task04_Hippocampus/2025-04-24_14-52-40\"\n",
    "model_dir_str = \"trained_models/ms-unet3d/Task01_BrainTumour/2025-05-07_19-45-45\"\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "\n",
    "model_dir = pathlib.Path(model_dir_str)\n",
    "if not model_dir.is_dir():\n",
    "    raise FileNotFoundError(f\"Model directory not found: {model_dir}\")\n",
    "\n",
    "model_path = f\"{model_dir}/best_model.pth\"\n",
    "cfg = OmegaConf.load(f\"{model_dir}/config.yaml\")\n",
    "\n",
    "\n",
    "try:\n",
    "    path_parts = model_dir.parts\n",
    "    # model_architechture = path_parts[-3]\n",
    "    task_name = path_parts[-2]\n",
    "    inference_model_name = path_parts[-1]\n",
    "except IndexError:\n",
    "    raise ValueError(f\"Could not parse architecture/task/name from model_dir: {model_dir}. Expected structure like 'trained_models/arch/task/name'\")\n",
    "\n",
    "if not isinstance(cfg, DictConfig):\n",
    "    raise TypeError(\"cfg must be a DictConfig.\")\n",
    "\n",
    "if task_name == \"Task04_Hippocampus\":\n",
    "    dataset = MedicalDecathlonDataset(cfg, \"test\")\n",
    "elif task_name == \"Task01_BrainTumour\":\n",
    "    dataset = BrainTumourDataset(cfg, \"test\") \n",
    "else:\n",
    "    raise ValueError(f\"Unknown task name: {task_name}. Expected 'Task04_Hippocampus' or 'Task01_BrainTumour'.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = instantiate(cfg.architecture.path, cfg)\n",
    "\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model_state_dict = checkpoint['model_state_dict']\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.to(device)  # Move the model to the appropriate device\n",
    "model.eval()\n",
    "\n",
    "\n",
    "#samples idx list to check: (6,)\n",
    "sample_idx = 0\n",
    "\n",
    "# ... after dataset creation ...\n",
    "print(f\"Dataset size (test phase): {len(dataset)}\")\n",
    "ensure(len(dataset) > 0, Exception, \"Dataset is empty!\")\n",
    "\n",
    "sample_idx = min(len(dataset)-1, 392) \n",
    "image, gt = dataset[sample_idx]\n",
    "# ... rest of the code ...\n",
    "\n",
    "image, gt = dataset[sample_idx]  # image: (C, D, H, W), gt: (D, H, W)\n",
    "\n",
    "# Add batch dimension and move to device\n",
    "image_batch = image.unsqueeze(0).to(device)  # shape: (1, C, D, H, W)\n",
    "print(f\"Image shape: {image_batch.shape}\")\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    output = model(image_batch)\n",
    "    # If model returns deep supervision outputs, take the final prediction\n",
    "    if isinstance(output, (tuple, list)):\n",
    "        output = output[0]\n",
    "    # Get predicted labels: (B, D, H, W)\n",
    "    pred = torch.argmax(output, dim=1).squeeze(0).cpu()  \n",
    "\n",
    "# Convert tensors to numpy arrays for visualization\n",
    "# Remove channel dimension from image for visualization: (D, H, W)\n",
    "image_np = image.squeeze(0).cpu().numpy()\n",
    "gt_np = gt.cpu().numpy()\n",
    "pred_np = pred.numpy()\n",
    "\n",
    "# Choose 3 slices evenly spaced along the depth dimension\n",
    "depth = image_np.shape[0]\n",
    "num_slices = min(depth, 66)\n",
    "slice_indices = np.linspace(0, depth-1, num=num_slices, dtype=int)\n",
    "\n",
    "\n",
    "# Create subplots: one row per slice and 3 columns for image, ground truth, and prediction\n",
    "fig, axes = plt.subplots(nrows=num_slices, ncols=3, figsize=(12, 4 * num_slices))\n",
    "for i, slice_idx in enumerate(slice_indices):\n",
    "    slice_2d = image_np[slice_idx]\n",
    "    # slice_2d = np.rot90(slice_2d)\n",
    "    axes[i, 0].imshow(slice_2d, cmap=\"gray\")\n",
    "    axes[i, 0].set_title(f\"Image Slice {slice_idx}\")\n",
    "    \n",
    "    gt_2d = gt_np[slice_idx]\n",
    "    # gt_2d = np.rot90(gt_2d)\n",
    "    axes[i, 1].imshow(gt_2d, cmap=\"grey\", vmin=0, vmax=cfg.dataset.num_classes - 1)\n",
    "\n",
    "    axes[i, 1].set_title(f\"Ground Truth Slice {slice_idx}\")\n",
    "    pred_2d = pred_np[slice_idx]\n",
    "    # pred_2d = np.rot90(pred_2d)\n",
    "    axes[i, 2].imshow(pred_2d, cmap=\"grey\", vmin=0, vmax=cfg.dataset.num_classes - 1)\n",
    "    axes[i, 2].set_title(f\"Prediction Slice {slice_idx}\")\n",
    "\n",
    "    # for ax in axes[i]:\n",
    "    #     ax.axis(\"off\")\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.__config__ import show\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show_prediction(image, gt_mask, pred_mask, slice_idx=None, class_id=1):\n",
    "    gt_binary = (gt_mask == class_id)\n",
    "    pred_binary = (pred_mask == class_id)\n",
    "\n",
    "    if slice_idx is None:\n",
    "        z_coords = np.where(gt_binary)[0]\n",
    "        slice_idx = z_coords[len(z_coords)//2] if len(z_coords) > 0 else gt_mask.shape[0] // 2\n",
    "\n",
    "    plt.figure(figsize=(16, 4))\n",
    "\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(image[slice_idx], cmap='gray')\n",
    "    plt.title(\"MRI Slice\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(gt_binary[slice_idx], cmap='gray')\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(pred_binary[slice_idx], cmap='gray')\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    error_map = np.logical_xor(gt_binary[slice_idx], pred_binary[slice_idx])\n",
    "    plt.imshow(error_map, cmap='Reds')\n",
    "    plt.title(\"Error Map\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.suptitle(f\"Class {class_id} - Slice {slice_idx}\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_prediction(image_np, gt_np, pred_np, class_id=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of images!\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models.ms_unet3d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MedicalDecathlonDataset, BrainTumourDataset\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mms_unet3d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MSUNet3D\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# ras+ ORIENTATION\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# class imbalance\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# task_name = \"Task04_Hippocampus\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m task_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask01_BrainTumour\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models.ms_unet3d'"
     ]
    }
   ],
   "source": [
    "from ast import mod\n",
    "import numpy as np\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import data\n",
    "from data.datasets import MedicalDecathlonDataset, BrainTumourDataset\n",
    "from models.ms_unet3d import MSUNet3D\n",
    "\n",
    "# ras+ ORIENTATION\n",
    "# class imbalance\n",
    "\n",
    "# task_name = \"Task04_Hippocampus\"\n",
    "task_name = \"Task01_BrainTumour\"\n",
    "inference_model_name = \"2025-03-31_13-44-04\"\n",
    "\n",
    "model_dir = f\"trained_models/unet3d/{task_name}/{inference_model_name}\"\n",
    "model_path = f\"{model_dir}/best_model.pth\"\n",
    "\n",
    "cfg = OmegaConf.load(f\"{model_dir}/config.yaml\")\n",
    "\n",
    "if not isinstance(cfg, DictConfig):\n",
    "    raise TypeError(\"cfg must be a DictConfig.\")\n",
    "\n",
    "dataset = MedicalDecathlonDataset(cfg, phase=\"test\")\n",
    "# dataset = BrainTumourDataset(cfg, phase='train')\n",
    "\n",
    "model = MSUNet3D(\n",
    "    in_channels=1,\n",
    "    num_classes=cfg.dataset.num_classes,\n",
    "    n_filters=cfg.model.n_filters,\n",
    "    dropout=cfg.training.dropout,\n",
    "    batch_norm=True,\n",
    "    inference_fusion_mode=cfg.model.deep_supervision.inference_fusion_mode,\n",
    "    depth=cfg.model.depth,\n",
    "    deep_supervision_levels=cfg.model.deep_supervision.levels\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize predetermined sample and random slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<data.datasets.MedicalDecathlonDataset object at 0x749135988d60>\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m sample_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset)\n\u001b[0;32m----> 3\u001b[0m image, gt \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_idx\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# image: (C, D, H, W), gt: (D, H, W)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mslice\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m104\u001b[39m \u001b[38;5;66;03m# or 126\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# three random slices\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Pick three random slices along the depth dimension\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/medsegnet/data/datasets.py:91\u001b[0m, in \u001b[0;36mMedicalDecathlonDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 91\u001b[0m     image, mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img_and_gts\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# Add channel dim and create subject\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     image \u001b[38;5;241m=\u001b[39m image[np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "File \u001b[0;32m~/Desktop/medsegnet/data/datasets.py:83\u001b[0m, in \u001b[0;36mMedicalDecathlonDataset.load_img_and_gts\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_img_and_gts\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 83\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages_path, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_files\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     84\u001b[0m     image \u001b[38;5;241m=\u001b[39m nib\u001b[38;5;241m.\u001b[39mas_closest_canonical(nib\u001b[38;5;241m.\u001b[39mload(image_path))\u001b[38;5;241m.\u001b[39mget_fdata()  \u001b[38;5;66;03m# [W, H, D]\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     mask_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasks_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_files[idx])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sample_idx = 300\n",
    "print(dataset)\n",
    "image, gt = dataset[sample_idx]  # image: (C, D, H, W), gt: (D, H, W)\n",
    "slice = 104 # or 126\n",
    "\n",
    "# three random slices\n",
    "# Pick three random slices along the depth dimension\n",
    "depth = image.shape[3]\n",
    "slices = np.random.choice(depth, size=3, replace=False)\n",
    "\n",
    "# Plot the slices\n",
    "for i, slice_idx in enumerate(slices):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.imshow(image[0, :, :, slice_idx], cmap='gray')\n",
    "    plt.title(f\"Slice {slice_idx}\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize predetermined sample and slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 300\n",
    "\n",
    "image, gt = dataset[sample_idx]  # image: (C, D, H, W), gt: (D, H, W)\n",
    "slice = 104 # or 126\n",
    "\n",
    "#Skew image\n",
    "\n",
    "\n",
    "plt.imshow(image[0, :, :, slice_idx], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization for experiments with multiscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Display Hippocampus Image at Multiple Scales\n",
    "#\n",
    "# This notebook loads a fixed hippocampus scan at several precomputed scales\n",
    "# and displays the central axial slice for each in a grid layout.\n",
    "\n",
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import math\n",
    "scales = [0, 1, 2, 3, 4, 5]\n",
    "# %%\n",
    "# Hardcoded file paths for each scale\n",
    "def get_paths():\n",
    "    base = 'datasets/Task04_Hippocampus_Scaled/imagesTs'\n",
    "    image = 'hippocampus_133'\n",
    "    return [\n",
    "        f\"{base}/scale{i}/{image}.nii\" for i in scales\n",
    "    ]\n",
    "\n",
    "paths = get_paths()\n",
    "titles = [f'scale{i}' for i in range(len(paths))]\n",
    "\n",
    "# %%\n",
    "# Load each volume and extract the central axial slice\n",
    "slices = []\n",
    "for path in paths:\n",
    "    img = nib.load(path)\n",
    "    data = img.get_fdata()               # shape (X, Y, Z)\n",
    "    z_mid = data.shape[2] // 2\n",
    "    axial_slice = data[:, :, z_mid]      # shape (X, Y)\n",
    "    slices.append(axial_slice)\n",
    "\n",
    "# %%\n",
    "# Plotting in a grid\n",
    "n = len(slices)\n",
    "cols = 3\n",
    "rows = math.ceil(n / cols)\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 4 * rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, slc, title in zip(axes, slices, titles):\n",
    "    ax.imshow(slc.T, cmap='gray', origin='lower')\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "\n",
    "# Hide any unused subplots\n",
    "for ax in axes[n:]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "image shape: (128, 256, 256, 4)\n",
      "image shape: torch.Size([4, 128, 256, 256])\n",
      "Image shape: torch.Size([4, 128, 256, 256])\n",
      "[Scale 0 | Image Shape torch.Size([1, 4, 128, 256, 256])\n",
      "[Scale 1 | Image Shape torch.Size([1, 4, 64, 128, 128])\n",
      "[Scale 2 | Image Shape torch.Size([1, 4, 32, 64, 64])\n",
      "[Scale 3 | Image Shape torch.Size([1, 4, 16, 32, 32])\n",
      "Results per scale:\n",
      "Scale 0: [7.230346182884873e-11, 0.06655266880989075, 0.0002643187763169408, 0.14068478345870972, 2.5335280748328692e-11, 4.294707700580602e-09, 2.0847227943932012e-08, 8.559564168564293e-10, 0.05867317318916321, 2.3406498961264788e-11, 0.014613794162869453, 0.22130432724952698, 0.007933494634926319, 0.19656281173229218, 0.1786474585533142, 0.00797295942902565, 0.008568576537072659, 0.14419284462928772, 9.914680187961267e-11, 0.3723772466182709, 0.002660837024450302, 0.00047596878721378744, 2.489487435641813e-11, 2.7888590742319863e-11, 2.830014521337798e-11, 0.017224343493580818, 0.05912042409181595, 2.4936865072877623e-11, 0.019165141507983208, 8.474929091839556e-11, 0.10008437931537628, 0.22863727807998657, 0.003650784259662032, 0.03663082420825958, 2.342112281894515e-09, 0.29517078399658203, 0.07971145212650299, 0.1449834406375885, 0.001919266302138567, 0.025227470323443413, 0.000294149067485705, 0.07604065537452698, 0.01625889539718628, 0.013589181005954742, 0.05227353796362877, 0.012796587310731411, 4.970012595917339e-11, 0.023569073528051376, 0.05359712988138199, 0.006527308374643326, 0.01311175711452961, 0.05799655243754387, 0.0018594914581626654, 4.982160239919153e-10, 0.007339925970882177, 3.829170314162411e-11, 0.010321389883756638, 3.311486154733423e-11, 0.018655376508831978, 1.0323143381785194e-11, 0.03958656266331673, 4.5264451908888503e-11, 2.178935504248969e-11, 0.00204882537946105, 1.899525502169208e-11, 0.13275396823883057, 0.002882246393710375, 2.148395350509702e-10, 0.0022021005861461163, 1.6053299314866543e-11, 0.07160204648971558, 0.05377815291285515, 0.1736806333065033, 3.258307165743268e-11, 0.21476195752620697, 0.0012157135643064976, 8.203197843226206e-11, 0.0642961636185646, 0.0033668065443634987, 0.10500016063451767, 0.40876322984695435, 0.0018937131389975548, 3.651095814571903e-10, 1.6677617620253216e-10, 0.08329783380031586, 0.011350761167705059, 3.675779125522638e-11, 0.014029167592525482, 0.07126471400260925, 0.0009301253012381494, 0.003555287141352892, 0.2781717777252197, 0.1117188036441803, 1.8440310389777892e-09, 0.1472281664609909, 0.00693381205201149, 3.297472711549787e-11]\n",
      "Mean Dice: 0.0495, Std Dice: 0.0836\n",
      "Scale 1: [5.265565761192192e-10, 0.06333643198013306, 0.00042600996675901115, 0.13921231031417847, 2.0650084420203996e-10, 3.0346751778154157e-09, 7.191213846624578e-09, 3.828410477524358e-09, 0.05972021445631981, 1.9974115417209504e-10, 0.013796502724289894, 0.2196938395500183, 0.010546447709202766, 0.20221975445747375, 0.1946241855621338, 0.0075558386743068695, 0.00861564464867115, 0.14617523550987244, 6.940730212789958e-10, 0.36802172660827637, 0.0022868344094604254, 0.00034671672619879246, 1.9924166483331618e-10, 2.0435353409453683e-10, 2.2397743382196467e-10, 0.02021830528974533, 0.06318418681621552, 2.0547988310859466e-10, 0.022936619818210602, 6.974871791243231e-10, 0.09725429117679596, 0.23062565922737122, 0.004037428181618452, 0.042621683329343796, 2.3155022788046153e-08, 0.30610474944114685, 0.08048474788665771, 0.14385421574115753, 0.002096504205837846, 0.029871728271245956, 0.0009067938663065434, 0.07609996199607849, 0.015934649854898453, 0.013768116012215614, 0.051939867436885834, 0.01299155130982399, 3.7435396449403413e-10, 0.02417214773595333, 0.053275641053915024, 0.00576718058437109, 0.013074396178126335, 0.059736691415309906, 0.0016767395427450538, 3.098679313140451e-09, 0.00642896443605423, 2.960269807061877e-10, 0.009964467957615852, 2.7040630845576175e-10, 0.020640607923269272, 8.080371788343754e-11, 0.041017185896635056, 3.830601391641153e-10, 1.743230004791485e-10, 0.005713560618460178, 1.511779035290317e-10, 0.10629384219646454, 0.008287448436021805, 1.5236449879552083e-09, 0.002338302554562688, 0.003606202779337764, 0.06773779541254044, 0.050459593534469604, 0.16413336992263794, 2.5566784800368225e-10, 0.21998731791973114, 2.39542585767083e-09, 6.894735338214275e-10, 0.06812439858913422, 0.0015018245903775096, 0.11046937108039856, 0.43660348653793335, 0.0018352585611864924, 2.654129138690564e-09, 1.5252207274940588e-09, 0.07937973737716675, 0.027591725811362267, 3.44632045123916e-10, 0.013427428901195526, 0.07258988916873932, 0.0007002357160672545, 0.003648863174021244, 0.30132779479026794, 0.1131129264831543, 1.4714869323029234e-08, 0.151333749294281, 0.00735586229711771, 2.6521515539279505e-10]\n",
      "Mean Dice: 0.0506, Std Dice: 0.0858\n",
      "Scale 2: [3.9103262849948806e-09, 0.06058578938245773, 9.113152454887086e-10, 0.13290932774543762, 1.629130053082406e-09, 0.0008182523306459188, 8.417861607767918e-08, 2.8761197867765986e-08, 0.06029277667403221, 1.5226324645567502e-09, 0.016235418617725372, 0.20672105252742767, 0.012680469080805779, 0.20496296882629395, 0.17941901087760925, 0.006895675789564848, 0.00537070631980896, 0.13343451917171478, 0.003828279674053192, 0.37372273206710815, 0.002004582667723298, 0.0011010193265974522, 1.5345387183174353e-09, 1.6280836678816968e-09, 1.7345562763892985e-09, 0.02098868414759636, 0.05692514777183533, 1.5691143939733365e-09, 0.02156611531972885, 6.939914865000674e-09, 0.10317754745483398, 0.22573626041412354, 0.004856513813138008, 0.035261865705251694, 0.3333333730697632, 0.3038443922996521, 0.07789646089076996, 0.15261535346508026, 0.0015596579760313034, 0.026002511382102966, 1.5167323397236032e-08, 0.06882452964782715, 0.012329824268817902, 0.014004737138748169, 0.04988391324877739, 0.011573383584618568, 2.8026310161521906e-09, 0.020658552646636963, 0.05314331874251366, 0.005767015274614096, 0.014512473717331886, 0.058988671749830246, 0.003835828509181738, 2.2294965873470574e-08, 0.0032136263325810432, 2.4505135698404956e-09, 0.009832842275500298, 2.180275515684116e-09, 0.01591293327510357, 6.904726790324389e-10, 0.038392066955566406, 3.1214195672646383e-09, 1.3537260201701429e-09, 0.016984164714813232, 1.2208187794016112e-09, 0.05087722837924957, 0.0019351919181644917, 1.1504262431571988e-08, 0.0029254043474793434, 1.0501925995498596e-09, 0.07061561942100525, 0.06196700036525726, 0.1767534464597702, 1.93625315780821e-09, 0.2407759726047516, 0.012698428705334663, 5.168955041767731e-09, 0.06239667162299156, 0.003498795907944441, 0.11556201428174973, 0.44751250743865967, 0.0022772569209337234, 4.317211832471912e-08, 1.0372224856780576e-08, 0.07562760263681412, 0.01862308382987976, 2.799421805477209e-09, 0.013290142640471458, 0.06850665807723999, 0.00016869242244865745, 0.006146762054413557, 0.26387497782707214, 0.11123737692832947, 1.7511267458303337e-07, 0.13397632539272308, 0.005862139165401459, 2.2350139516902345e-09]\n",
      "Mean Dice: 0.0527, Std Dice: 0.0895\n",
      "Scale 3: [1.8588785621886927e-08, 0.07505520433187485, 7.100662280379311e-09, 0.12602470815181732, 1.609126876189748e-08, 9.036011050511661e-08, 0.3333333432674408, 6.382546047234428e-08, 0.06228957325220108, 1.213601485972049e-08, 0.03846157342195511, 0.2380726933479309, 0.013933394104242325, 0.26902222633361816, 0.24925844371318817, 0.005602251272648573, 0.0046620117500424385, 0.11021144688129425, 5.080227083453792e-08, 0.3964702785015106, 5.5885651661924385e-09, 8.021034503258306e-09, 1.1476987360481417e-08, 1.528225368474523e-08, 1.2392017190165916e-08, 0.035794228315353394, 0.036175720393657684, 1.4641822865257836e-08, 0.01579780876636505, 4.04252062935484e-08, 0.06892423331737518, 0.2120674103498459, 8.936421380667525e-09, 0.3333333730697632, 0.6666666865348816, 0.18444445729255676, 0.07834511995315552, 0.5581395626068115, 6.703047006340057e-09, 0.01724141277372837, 7.345222030608056e-08, 0.047257136553525925, 0.014154292643070221, 0.008726011961698532, 0.04864567145705223, 0.00859107542783022, 2.3847590568948362e-08, 0.03165918216109276, 0.0572681799530983, 1.7296192922344744e-08, 0.014035103842616081, 0.05927571654319763, 1.5163884370394953e-08, 6.090668591696158e-08, 4.828359934094806e-09, 1.2206399446768046e-08, 0.008250832557678223, 1.9068824741452772e-08, 0.008281784132122993, 5.9400813157139964e-09, 0.02156124822795391, 2.152306421976391e-08, 1.135290528253563e-08, 0.009061500430107117, 9.78592140654655e-09, 0.33333349227905273, 0.009070375934243202, 1.4393937419754366e-07, 0.0029304155614227057, 8.806201989841611e-09, 0.06980805099010468, 0.037853676825761795, 0.1943056285381317, 1.9007323714959057e-08, 0.20364198088645935, 2.8333323598417337e-07, 3.472566589834969e-08, 0.061164408922195435, 0.003418808337301016, 0.11754991114139557, 0.4884079396724701, 6.418282794129482e-09, 1.7741695046424866e-07, 9.1464059437385e-08, 0.0744771957397461, 0.033431679010391235, 1.7224451198671886e-08, 0.005486985202878714, 0.06984128057956696, 1.4276397841683774e-08, 0.0032760780304670334, 0.1957557499408722, 0.10792875289916992, 0.3333333730697632, 0.14369049668312073, 5.780433465218948e-09, 1.671393867752613e-08]\n",
      "Mean Dice: 0.0717, Std Dice: 0.1292\n",
      "Scale 4: []\n",
      "Mean Dice: nan, Std Dice: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/si-hj/.conda/envs/bp/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/si-hj/.conda/envs/bp/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/si-hj/.conda/envs/bp/lib/python3.10/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/si-hj/.conda/envs/bp/lib/python3.10/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/si-hj/.conda/envs/bp/lib/python3.10/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "model_dir_str = \"trained_models/ms-unet3d/Task01_BrainTumour/2025-05-07_23-36-36\"\n",
    "model_path, cfg = model_params(model_dir_str)\n",
    "\n",
    "\n",
    "base_dir = Path(\"datasets/Task01_BrainTumour_Scaled\")\n",
    "img_dir = base_dir / \"imagesTs\" / f\"scale0\"\n",
    "lbl_dir = base_dir / \"labelsTs\" / f\"scale0\"\n",
    "img_dir_sort = sorted(os.listdir(img_dir))\n",
    "lbl_dir_sort = sorted(os.listdir(lbl_dir))\n",
    "test_dataset = BrainTumourDataset(cfg, \"test\", img_dir_sort, lbl_dir_sort, str(img_dir), str(lbl_dir))\n",
    "\n",
    "setup_seed(cfg.seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = instantiate(cfg.architecture.path, cfg)\n",
    "\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model_state_dict = checkpoint[\"model_state_dict\"]\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "results_per_scale = {scale: [] for scale in [0, 1, 2, 3]}\n",
    "\n",
    "for image, label in test_dataset:\n",
    "    print(f\"Image shape: {image.shape}\")\n",
    "    image_tensor = image.unsqueeze(0).to(device)\n",
    "    \n",
    "    segs, _ = model(image_tensor)\n",
    "    for i in range(len(segs)):\n",
    "        print(f\"[Scale {i} | Image Shape {segs[i].shape}\")\n",
    "        preds = segs[i]\n",
    "        pred = torch.argmax(preds, dim=1).squeeze(0)\n",
    "        label = label.squeeze(0).to(device)\n",
    "        downsampled_label = F.interpolate(\n",
    "                    label.unsqueeze(0).unsqueeze(0).float(),\n",
    "                    size=pred.shape,\n",
    "                    mode=\"nearest\",\n",
    "                ).squeeze(0).squeeze(0)\n",
    "        d = dice_coefficient(\n",
    "            pred, downsampled_label, num_classes=cfg.dataset.num_classes, ignore_index=0\n",
    "        )\n",
    "        results_per_scale[i] += [d.item()]\n",
    "print(\"Results per scale:\")\n",
    "for scale, results in results_per_scale.items():\n",
    "    print(f\"Scale {scale}: {results}\")\n",
    "    mean_dice = np.mean(results)\n",
    "    std_dice = np.std(results)\n",
    "    print(f\"Mean Dice: {mean_dice:.4f}, Std Dice: {std_dice:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
