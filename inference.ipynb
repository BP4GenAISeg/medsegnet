{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import mod\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from typing import Dict, Tuple\n",
    "import torchio as tio\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import data\n",
    "from data.datasets import MedicalDecathlonDataset, BrainTumourDataset\n",
    "from utils.assertions import ensure\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def model_params(model_dir_str):\n",
    "\tmodel_dir = Path(model_dir_str)\n",
    "\tif not model_dir.is_dir():\n",
    "\t\traise FileNotFoundError(f\"Model directory not found: {model_dir}\")\n",
    "\t\n",
    "\tmodel_path = f\"{model_dir}/best_model.pth\"\n",
    "\tcfg = OmegaConf.load(f\"{model_dir}/config.yaml\")\n",
    "\n",
    "\tif not isinstance(cfg, DictConfig):\n",
    "\t\traise TypeError(\"cfg must be a DictConfig.\")\n",
    "\n",
    "\treturn model_path, cfg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasimulation \n",
    "### DataSimulation -- Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************* TEST 2 *******************\n",
      "Results per scale:\n",
      "Scale 0: [0.8697332143783569, 0.8908807635307312, 0.89766526222229, 0.9034327268600464, 0.8923261165618896, 0.9137741327285767, 0.8935537338256836, 0.9274379014968872, 0.9222763180732727, 0.9228132367134094, 0.8982306122779846, 0.9209433794021606, 0.9095128774642944, 0.8946025371551514, 0.8408000469207764, 0.9218124151229858, 0.9051204919815063, 0.8797208666801453, 0.9019480347633362, 0.899074912071228, 0.8909603953361511, 0.8282102346420288, 0.8848001956939697, 0.8778936862945557, 0.8862123489379883, 0.9274997115135193, 0.9150633215904236, 0.9023410081863403, 0.9110750555992126, 0.9126946330070496, 0.8430639505386353, 0.9013086557388306, 0.9320898056030273, 0.8501603603363037, 0.9063147306442261, 0.8714383840560913, 0.891387939453125, 0.9138755798339844, 0.9077775478363037, 0.8199940919876099, 0.8647392988204956, 0.8504270911216736, 0.8959993124008179, 0.8683866262435913, 0.8155511617660522, 0.83397376537323, 0.8774942755699158, 0.869408369064331, 0.8996055722236633, 0.9015187621116638, 0.8682057857513428, 0.8976039290428162]\n",
      "Mean Dice: 0.8889, Std Dice: 0.0284\n",
      "Scale 1: [0.8592919707298279, 0.9003264904022217, 0.8678494691848755, 0.8795045614242554, 0.8733552694320679, 0.9132897853851318, 0.885068416595459, 0.9231219291687012, 0.9118318557739258, 0.9243037104606628, 0.8659371137619019, 0.905171275138855, 0.8850691318511963, 0.8680366277694702, 0.8621417880058289, 0.8961886763572693, 0.8946714401245117, 0.8772833347320557, 0.8861047029495239, 0.8593908548355103, 0.8777487277984619, 0.7978541851043701, 0.8872628808021545, 0.8436449766159058, 0.8788660764694214, 0.9023621082305908, 0.9007315635681152, 0.8811244964599609, 0.8760249614715576, 0.9178577065467834, 0.7661975622177124, 0.8988046050071716, 0.9053849577903748, 0.859676718711853, 0.8845437169075012, 0.8411113023757935, 0.8581697940826416, 0.8897498250007629, 0.9100353121757507, 0.7785502076148987, 0.8214452266693115, 0.8355826139450073, 0.8707501292228699, 0.8385884165763855, 0.8518518209457397, 0.8157970905303955, 0.8824343681335449, 0.8373808860778809, 0.9150949120521545, 0.8716671466827393, 0.8563230037689209, 0.8502407073974609]\n",
      "Mean Dice: 0.8719, Std Dice: 0.0342\n",
      "Scale 2: [0.854387640953064, 0.8234920501708984, 0.8795066475868225, 0.8709766864776611, 0.8382176160812378, 0.866310179233551, 0.8595387935638428, 0.8671485185623169, 0.8786797523498535, 0.8821924924850464, 0.8421568870544434, 0.8628205060958862, 0.7996130585670471, 0.898483395576477, 0.8445748090744019, 0.8200430870056152, 0.808161735534668, 0.8574999570846558, 0.9075098633766174, 0.8285714387893677, 0.8304597735404968, 0.7348659038543701, 0.8774999976158142, 0.7945301532745361, 0.8720598220825195, 0.8399814367294312, 0.8442553281784058, 0.8458635807037354, 0.8067796230316162, 0.8642987012863159, 0.7380597591400146, 0.8831169009208679, 0.9002695083618164, 0.8747825622558594, 0.7903861403465271, 0.8184523582458496, 0.8710119724273682, 0.8614097833633423, 0.919459342956543, 0.7529850602149963, 0.7651515007019043, 0.7546584010124207, 0.8291517496109009, 0.7425937652587891, 0.8784786462783813, 0.8026931881904602, 0.8461996912956238, 0.8510972261428833, 0.928205132484436, 0.7977067828178406, 0.75, 0.7815126180648804]\n",
      "Mean Dice: 0.8373, Std Dice: 0.0478\n",
      "Scale 3: [1.0, 0.7083333730697632, 0.761904776096344, 0.7000000476837158, 0.8999999761581421, 1.0, 0.6500000953674316, 0.6507936716079712, 0.6190477013587952, 0.8035714626312256, 0.8444444537162781, 0.730158805847168, 0.8999999761581421, 0.8730158805847168, 0.875, 0.9285714626312256, 0.800000011920929, 0.800000011920929, 1.0, 0.785714328289032, 0.9285714626312256, 0.6666667461395264, 0.9285714626312256, 0.20000016689300537, 0.8999999761581421, 1.0, 0.8333333730697632, 0.7083333730697632, 0.9285714626312256, 0.785714328289032, 0.33333343267440796, 0.6857143640518188, 0.8333333730697632, 0.8999999761581421, 0.5666667222976685, 0.6250000596046448, 0.8285714387893677, 0.7619048357009888, 0.8999999761581421, 0.28571438789367676, 0.8333333730697632, 0.6666667461395264, 0.625, 1.0, 1.0, 0.7333333492279053, 0.9444444179534912, 0.8285714387893677, 0.7619048357009888, 0.785714328289032, 0.8035714626312256, 0.875]\n",
      "Mean Dice: 0.7844, Std Dice: 0.1706\n",
      "Scale 4: [0.5000004768371582, 0.5000004768371582, 0.5000002384185791, 0.5000004768371582, 0.5000004768371582, 0.5000004768371582, 0.5000004768371582, 0.5000004768371582, 1.0, 0.5000004768371582, 0.5000004768371582, 1.0, 0.5000004768371582, 0.5000004768371582, 1.0, 1.0, 0.5000004768371582, 0.5000004768371582, 0.5000004768371582, 0.5000004768371582, 0.5000004768371582, 0.5000004768371582, 0.5000004768371582, 0.5000002384185791, 0.5000004768371582, 1.0, 1.0, 0.5000004768371582, 0.5000004768371582, 0.5000004768371582, 1.0, 0.5000004768371582, 0.5000004768371582, 0.5000004768371582, 0.5000004768371582, 0.5000004768371582, 0.5000004768371582, 0.5000004768371582, 0.5000004768371582, 0.5000004768371582, 0.5000004768371582, 1.0, 0.5000002384185791, 1.0, 0.5000004768371582, 0.5000002384185791, 0.5000004768371582, 0.5000004768371582, 0.5000004768371582, 0.5000004768371582, 0.5000004768371582, 0.5000004768371582]\n",
      "Mean Dice: 0.5865, Std Dice: 0.1892\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import nibabel as nib\n",
    "from utils.metrics import dice_coefficient, dice_coefficient_classes\n",
    "from utils.utils import setup_seed\n",
    "from hydra.utils import instantiate\n",
    "import os\n",
    "from data.datasets import MedicalDecathlonDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# model_dir_str = \"trained_models/ms-unet3d/Task04_Hippocampus/2025-05-05_12-17-39\"\n",
    "model_dir_str = \"trained_models/ms-unet3d/Task04_Hippocampus/2025-05-07_15-16-30\"\n",
    "\n",
    "model_path, cfg = model_params(model_dir_str)\n",
    "scales = [0, 1, 2, 3, 4]\n",
    "\n",
    "base_dir = Path(cfg.dataset.base_path)\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for scale in scales:\n",
    "\timg_dir = base_dir / \"imagesTs\" / f\"scale{scale}\"\n",
    "\tlbl_dir = base_dir / \"labelsTs\" / f\"scale{scale}\"\n",
    "\timg_dir_sort = sorted(os.listdir(img_dir))\n",
    "\tlbl_dir_sort = sorted(os.listdir(lbl_dir))\n",
    "\tdataset = MedicalDecathlonDataset(cfg, \"test\", img_dir_sort, lbl_dir_sort, str(img_dir), str(lbl_dir))\n",
    "\tdatasets[scale] = dataset\n",
    "\n",
    "\n",
    "setup_seed(cfg.seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = instantiate(cfg.architecture.path, cfg)\n",
    "\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model_state_dict = checkpoint[\"model_state_dict\"]\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "results_per_scale = {scale: [] for scale in scales}\n",
    "# print(\"******************* TEST 1 *******************\")\n",
    "# print(\"THIS ASSUMES DATASET IS TARGET_SHAPE I THINK? I REMOVED THE TARGET SHAPE PADDING TO TEST BELOW TEST 2...\")\n",
    "# for image, label in datasets[0]:\n",
    "# \timage_tensor = image.unsqueeze(0).to(device)\n",
    "# \tsegs, _ = model(image_tensor)\n",
    "# \tfor i in range(len(segs)):\n",
    "# \t\tprint(f\"[Scale {i} | Image Shape {segs[i].shape}\")\n",
    "# \t\tpreds = segs[i]\n",
    "# \t\tpred = torch.argmax(preds, dim=1).squeeze(0)\n",
    "# \t\tlabel = label.squeeze(0).to(device)\n",
    "# \t\tdownsampled_label = F.interpolate(\n",
    "# \t\t\t\t\tlabel.unsqueeze(0).unsqueeze(0).float(),\n",
    "# \t\t\t\t\tsize=pred.shape,\n",
    "# \t\t\t\t\tmode=\"nearest\",\n",
    "# \t\t\t\t).squeeze(0).squeeze(0)\n",
    "# \t\td = dice_coefficient(\n",
    "# \t\t\tpred, downsampled_label, num_classes=cfg.dataset.num_classes, ignore_index=0\n",
    "# \t\t)\n",
    "# \t\tresults_per_scale[i] += [d.item()]\n",
    "  \n",
    "  \n",
    "# print(\"Results per scale:\")\n",
    "# for scale, results in results_per_scale.items():\n",
    "# \tprint(f\"Scale {scale}: {results}\")\n",
    "# \tmean_dice = np.mean(results)\n",
    "# \tstd_dice = np.std(results)\n",
    "# \tprint(f\"Mean Dice: {mean_dice:.4f}, Std Dice: {std_dice:.4f}\")\n",
    "\n",
    "\n",
    "results_per_scale = {scale: [] for scale in scales}\n",
    "print(\"******************* TEST 2 *******************\")\n",
    "for scale in scales:\n",
    "\twith torch.no_grad():\n",
    "\t\tfor image, label in datasets[scale]:\n",
    "\t\t\timage_tensor = image.unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "\t\t\t# print(image.shape)\n",
    "\t\t\t# print(f\"[Scale {scale} | Image Shape {image_tensor.shape}\")\n",
    "\t\t\t# print(f\"[Scale {scale} | Label Shape nig {label.shape}\")\n",
    "\n",
    "\t\t\toutput = model.run_inference(image_tensor)\n",
    "   \n",
    "\t\t\tlabel = label.squeeze(0).to(device)\n",
    "\t\t\tpred = torch.argmax(output, dim=1)\n",
    "\t\t\td = dice_coefficient(\n",
    "\t\t\t\tpred, label, num_classes=cfg.dataset.num_classes, ignore_index=0\n",
    "\t\t\t)\n",
    "\t\t\tresults_per_scale[scale] += [d.item()]\n",
    "\n",
    "\n",
    "print(\"Results per scale:\")\n",
    "for scale, results in results_per_scale.items():\n",
    "    print(f\"Scale {scale}: {results}\")\n",
    "    mean_dice = np.mean(results)\n",
    "    std_dice = np.std(results)\n",
    "    print(f\"Mean Dice: {mean_dice:.4f}, Std Dice: {std_dice:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSimulation -- BackBone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import mod\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import data\n",
    "from data.datasets import MedicalDecathlonDataset, BrainTumourDataset\n",
    "from models.unet3d import UNet3D\n",
    "\n",
    "from models.factory import create_model\n",
    "from utils.assertions import ensure\n",
    "\n",
    "\n",
    "# ------ Change only this for test of a trained model ------\n",
    "model_dir_str = \"trained_models/ms-unet3d/Task04_Hippocampus/2025-04-24_14-52-40\"\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "\n",
    "model_dir = pathlib.Path(model_dir_str)\n",
    "if not model_dir.is_dir():\n",
    "    raise FileNotFoundError(f\"Model directory not found: {model_dir}\")\n",
    "\n",
    "model_path = f\"{model_dir}/best_model.pth\"\n",
    "cfg = OmegaConf.load(f\"{model_dir}/config.yaml\")\n",
    "\n",
    "\n",
    "try:\n",
    "    path_parts = model_dir.parts\n",
    "    # model_architechture = path_parts[-3]\n",
    "    task_name = path_parts[-2]\n",
    "    inference_model_name = path_parts[-1]\n",
    "except IndexError:\n",
    "    raise ValueError(f\"Could not parse architecture/task/name from model_dir: {model_dir}. Expected structure like 'trained_models/arch/task/name'\")\n",
    "\n",
    "if not isinstance(cfg, DictConfig):\n",
    "    raise TypeError(\"cfg must be a DictConfig.\")\n",
    "\n",
    "if task_name == \"Task04_Hippocampus\":\n",
    "    dataset = MedicalDecathlonDataset(cfg, \"test\")\n",
    "elif task_name == \"Task01_BrainTumour\":\n",
    "    dataset = BrainTumourDataset(cfg, \"test\") \n",
    "else:\n",
    "    raise ValueError(f\"Unknown task name: {task_name}. Expected 'Task04_Hippocampus' or 'Task01_BrainTumour'.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = cfg.active_architecture\n",
    "\n",
    "model = create_model(cfg, model_name).to(device)\n",
    "\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model_state_dict = checkpoint['model_state_dict']\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.to(device)  # Move the model to the appropriate device\n",
    "model.eval()\n",
    "\n",
    "\n",
    "#samples idx list to check: (6,)\n",
    "sample_idx = 0\n",
    "\n",
    "# ... after dataset creation ...\n",
    "print(f\"Dataset size (test phase): {len(dataset)}\")\n",
    "ensure(len(dataset) > 0, Exception, \"Dataset is empty!\")\n",
    "\n",
    "sample_idx = min(len(dataset)-1, 392) \n",
    "image, gt = dataset[sample_idx]\n",
    "# ... rest of the code ...\n",
    "\n",
    "image, gt = dataset[sample_idx]  # image: (C, D, H, W), gt: (D, H, W)\n",
    "\n",
    "# Add batch dimension and move to device\n",
    "image_batch = image.unsqueeze(0).to(device)  # shape: (1, C, D, H, W)\n",
    "print(f\"Image shape: {image_batch.shape}\")\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    output = model(image_batch)\n",
    "    # If model returns deep supervision outputs, take the final prediction\n",
    "    if isinstance(output, (tuple, list)):\n",
    "        output = output[0]\n",
    "    # Get predicted labels: (B, D, H, W)\n",
    "    pred = torch.argmax(output, dim=1).squeeze(0).cpu()  \n",
    "\n",
    "# Convert tensors to numpy arrays for visualization\n",
    "# Remove channel dimension from image for visualization: (D, H, W)\n",
    "image_np = image.squeeze(0).cpu().numpy()\n",
    "gt_np = gt.cpu().numpy()\n",
    "pred_np = pred.numpy()\n",
    "\n",
    "# Choose 3 slices evenly spaced along the depth dimension\n",
    "depth = image_np.shape[0]\n",
    "num_slices = min(depth, 66)\n",
    "slice_indices = np.linspace(0, depth-1, num=num_slices, dtype=int)\n",
    "\n",
    "\n",
    "# Create subplots: one row per slice and 3 columns for image, ground truth, and prediction\n",
    "fig, axes = plt.subplots(nrows=num_slices, ncols=3, figsize=(12, 4 * num_slices))\n",
    "for i, slice_idx in enumerate(slice_indices):\n",
    "    slice_2d = image_np[slice_idx]\n",
    "    # slice_2d = np.rot90(slice_2d)\n",
    "    axes[i, 0].imshow(slice_2d, cmap=\"gray\")\n",
    "    axes[i, 0].set_title(f\"Image Slice {slice_idx}\")\n",
    "    \n",
    "    gt_2d = gt_np[slice_idx]\n",
    "    # gt_2d = np.rot90(gt_2d)\n",
    "    axes[i, 1].imshow(gt_2d, cmap=\"grey\", vmin=0, vmax=cfg.dataset.num_classes - 1)\n",
    "\n",
    "    axes[i, 1].set_title(f\"Ground Truth Slice {slice_idx}\")\n",
    "    pred_2d = pred_np[slice_idx]\n",
    "    # pred_2d = np.rot90(pred_2d)\n",
    "    axes[i, 2].imshow(pred_2d, cmap=\"grey\", vmin=0, vmax=cfg.dataset.num_classes - 1)\n",
    "    axes[i, 2].set_title(f\"Prediction Slice {slice_idx}\")\n",
    "\n",
    "    # for ax in axes[i]:\n",
    "    #     ax.axis(\"off\")\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.__config__ import show\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show_prediction(image, gt_mask, pred_mask, slice_idx=None, class_id=1):\n",
    "    gt_binary = (gt_mask == class_id)\n",
    "    pred_binary = (pred_mask == class_id)\n",
    "\n",
    "    if slice_idx is None:\n",
    "        z_coords = np.where(gt_binary)[0]\n",
    "        slice_idx = z_coords[len(z_coords)//2] if len(z_coords) > 0 else gt_mask.shape[0] // 2\n",
    "\n",
    "    plt.figure(figsize=(16, 4))\n",
    "\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(image[slice_idx], cmap='gray')\n",
    "    plt.title(\"MRI Slice\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(gt_binary[slice_idx], cmap='gray')\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(pred_binary[slice_idx], cmap='gray')\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    error_map = np.logical_xor(gt_binary[slice_idx], pred_binary[slice_idx])\n",
    "    plt.imshow(error_map, cmap='Reds')\n",
    "    plt.title(\"Error Map\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.suptitle(f\"Class {class_id} - Slice {slice_idx}\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_prediction(image_np, gt_np, pred_np, class_id=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of images!\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models.ms_unet3d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MedicalDecathlonDataset, BrainTumourDataset\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mms_unet3d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MSUNet3D\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# ras+ ORIENTATION\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# class imbalance\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# task_name = \"Task04_Hippocampus\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m task_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask01_BrainTumour\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models.ms_unet3d'"
     ]
    }
   ],
   "source": [
    "from ast import mod\n",
    "import numpy as np\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import data\n",
    "from data.datasets import MedicalDecathlonDataset, BrainTumourDataset\n",
    "from models.ms_unet3d import MSUNet3D\n",
    "\n",
    "# ras+ ORIENTATION\n",
    "# class imbalance\n",
    "\n",
    "# task_name = \"Task04_Hippocampus\"\n",
    "task_name = \"Task01_BrainTumour\"\n",
    "inference_model_name = \"2025-03-31_13-44-04\"\n",
    "\n",
    "model_dir = f\"trained_models/unet3d/{task_name}/{inference_model_name}\"\n",
    "model_path = f\"{model_dir}/best_model.pth\"\n",
    "\n",
    "cfg = OmegaConf.load(f\"{model_dir}/config.yaml\")\n",
    "\n",
    "if not isinstance(cfg, DictConfig):\n",
    "    raise TypeError(\"cfg must be a DictConfig.\")\n",
    "\n",
    "dataset = MedicalDecathlonDataset(cfg, phase=\"test\")\n",
    "# dataset = BrainTumourDataset(cfg, phase='train')\n",
    "\n",
    "model = MSUNet3D(\n",
    "    in_channels=1,\n",
    "    num_classes=cfg.dataset.num_classes,\n",
    "    n_filters=cfg.model.n_filters,\n",
    "    dropout=cfg.training.dropout,\n",
    "    batch_norm=True,\n",
    "    inference_fusion_mode=cfg.model.deep_supervision.inference_fusion_mode,\n",
    "    depth=cfg.model.depth,\n",
    "    deep_supervision_levels=cfg.model.deep_supervision.levels\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize predetermined sample and random slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<data.datasets.MedicalDecathlonDataset object at 0x749135988d60>\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m sample_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset)\n\u001b[0;32m----> 3\u001b[0m image, gt \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_idx\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# image: (C, D, H, W), gt: (D, H, W)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mslice\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m104\u001b[39m \u001b[38;5;66;03m# or 126\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# three random slices\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Pick three random slices along the depth dimension\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/medsegnet/data/datasets.py:91\u001b[0m, in \u001b[0;36mMedicalDecathlonDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 91\u001b[0m     image, mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img_and_gts\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# Add channel dim and create subject\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     image \u001b[38;5;241m=\u001b[39m image[np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "File \u001b[0;32m~/Desktop/medsegnet/data/datasets.py:83\u001b[0m, in \u001b[0;36mMedicalDecathlonDataset.load_img_and_gts\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_img_and_gts\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 83\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages_path, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_files\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     84\u001b[0m     image \u001b[38;5;241m=\u001b[39m nib\u001b[38;5;241m.\u001b[39mas_closest_canonical(nib\u001b[38;5;241m.\u001b[39mload(image_path))\u001b[38;5;241m.\u001b[39mget_fdata()  \u001b[38;5;66;03m# [W, H, D]\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     mask_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasks_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_files[idx])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sample_idx = 300\n",
    "print(dataset)\n",
    "image, gt = dataset[sample_idx]  # image: (C, D, H, W), gt: (D, H, W)\n",
    "slice = 104 # or 126\n",
    "\n",
    "# three random slices\n",
    "# Pick three random slices along the depth dimension\n",
    "depth = image.shape[3]\n",
    "slices = np.random.choice(depth, size=3, replace=False)\n",
    "\n",
    "# Plot the slices\n",
    "for i, slice_idx in enumerate(slices):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.imshow(image[0, :, :, slice_idx], cmap='gray')\n",
    "    plt.title(f\"Slice {slice_idx}\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize predetermined sample and slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 300\n",
    "\n",
    "image, gt = dataset[sample_idx]  # image: (C, D, H, W), gt: (D, H, W)\n",
    "slice = 104 # or 126\n",
    "\n",
    "#Skew image\n",
    "\n",
    "\n",
    "plt.imshow(image[0, :, :, slice_idx], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization for experiments with multiscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Display Hippocampus Image at Multiple Scales\n",
    "#\n",
    "# This notebook loads a fixed hippocampus scan at several precomputed scales\n",
    "# and displays the central axial slice for each in a grid layout.\n",
    "\n",
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import math\n",
    "scales = [0, 1, 2, 3, 4, 5]\n",
    "# %%\n",
    "# Hardâ€‘coded file paths for each scale\n",
    "def get_paths():\n",
    "    base = 'datasets/Task04_Hippocampus_Scaled/imagesTs'\n",
    "    image = 'hippocampus_133'\n",
    "    return [\n",
    "        f\"{base}/scale{i}/{image}.nii\" for i in scales\n",
    "    ]\n",
    "\n",
    "paths = get_paths()\n",
    "titles = [f'scale{i}' for i in range(len(paths))]\n",
    "\n",
    "# %%\n",
    "# Load each volume and extract the central axial slice\n",
    "slices = []\n",
    "for path in paths:\n",
    "    img = nib.load(path)\n",
    "    data = img.get_fdata()               # shape (X, Y, Z)\n",
    "    z_mid = data.shape[2] // 2\n",
    "    axial_slice = data[:, :, z_mid]      # shape (X, Y)\n",
    "    slices.append(axial_slice)\n",
    "\n",
    "# %%\n",
    "# Plotting in a grid\n",
    "n = len(slices)\n",
    "cols = 3\n",
    "rows = math.ceil(n / cols)\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 4 * rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, slc, title in zip(axes, slices, titles):\n",
    "    ax.imshow(slc.T, cmap='gray', origin='lower')\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "\n",
    "# Hide any unused subplots\n",
    "for ax in axes[n:]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
