# Hardware settings (applies globally)
gpu:
  mode: "single"         # Options: "single", "multi"
  devices: [1]           # e.g., [0, 1, 2, 3] for multi-GPU
  backend: "nccl"        # "nccl" for GPU, "gloo" for CPU

# Logging settings
tracking:
  log_to_wandb: false 
  wandb_project: "MedicalSegmentation" 
  # Dynamic name, so like "unet_lr_1e-4_wd_1e-7_{date}"
  # Then its really use to compare in graphs between runs
  run_name: "unet_pat_7_${now:%Y-%m-%d_%H-%M-%S}" 
  


# -- Active architechture selection --
active_architecture: simonmsdyn-unet3d

# -- Active dataset selection --
# active_dataset: Task01_BrainTumour
active_dataset: Task04_Hippocampus
# active_dataset: Task09_Spleen

# 42 is our defualt seed, so most of the code is decently reproduceable with 42
seed: 42 # None for no seed and integer for a numbered seed


# Model storage
trained_models:
  base_dir: "trained_models"


# **********************************************************************
# *                        ðŸš« DO NOT EDIT DEFAULTS! ðŸš«                 *
# *  The following settings are defaults and will be overwritten by    *
# *  dataset-specific overrides.                                       *
# **********************************************************************
architectures:
  simonmsdyn-unet3d:
    model_defaults:                         # Only configuration for the model
      depth: 4         
      in_channels: 1
      n_filters: 8
      deep_supervision:                     # TODO consider change to 'ds'
        enabled: true                       # Training with deep supervision
        multi_scaling: true                 # 
        levels: 3
        inference_fusion_mode: 'only_final' # Options: 'weighted_softmax', 'weighted_majority', 'only_final'
      loss:
        name: "CombinedLoss"
        params:
          alpha: 0.35                        # alpha * CrossEntropy + (1 - alpha) * DiceLoss
          ignore_index: null                 # 0 for no ignore, null for None
    training_defaults:    
      early_stopping: #set null if disable
        patience: 15
        verbose: true
        delta: 1e-3
        criterion: 'loss'
      scheduler: 
        _target_: torch.optim.lr_scheduler.StepLR
        step_size: 30 # Decay LR every 30 epochs
        gamma: 0.1    # Multiply LR by 0.1
      optimizer: 
        _target_: torch.optim.AdamW
        params: 
          lr: 3e-4
          weight_decay: 1e-4
      batch_size: 2
      num_epochs: 100
      batch_norm: True
      dropout: 0.1
      drop_last: True
      patience: 5

    
  # diffnet:
  #   model:
  #     timesteps: 1000
  #     beta_schedule: "linear"
  #     loss:
  #       name: "MSE"
  #   training_defaults:
  #     batch_size: 4
  #     learning_rate: 2e-4
  #     num_epochs: 200
# **********************************************************************
# *                  âœ… DEFAULTS SECTION ENDED - EDIT BELOW âœ…         *
# **********************************************************************

# Dataset configurations
datasets:
  Task01_BrainTumour:
    target_shape: [256, 256, 160]
    base_path: "datasets/Task01_BrainTumour/"
    images_subdir: "imagesTr"
    labels_subdir: "labelsTr"
    num_classes: 4
    overrides:
      training:
        batch_size: 1
        num_epochs: 100
        patience: 15
      model: 
        depth: 5
        in_channels: 1 # (flair, t1, ...)
        n_filters: 16
        deep_supervision:
          enabled: true
          levels: 4
          inference_fusion_mode: 'weighted_softmax'
        loss: 
          name: "CombinedLoss"
          params:
            alpha: 0.3
            ignore_index: 0


  Task02_Heart:
    target_shape: [256, 256, 128]
    base_path: "datasets/Task02_Heart/"
    images_subdir: "imagesTr"
    labels_subdir: "labelsTr"
    num_classes: 2

  Task03_Liver:
    target_shape: [512, 512, 64]
    base_path: "datasets/Task03_Liver/"
    images_subdir: "imagesTr"
    labels_subdir: "labelsTr"
    num_classes: 3

  Task04_Hippocampus:
    target_shape: [32, 64, 32]
    base_path: "datasets/Task04_Hippocampus/"
    images_subdir: "imagesTr"
    labels_subdir: "labelsTr"
    num_classes: 3
    overrides:
      training:
        batch_size: 2
        num_epochs: 200
        dropout: 0.3
        drop_last: false
        patience: 7
      model: 
        depth: 4
        n_filters: 8
        deep_supervision:
          enabled: true
          levels: 4
          inference_fusion_mode: 'weighted_softmax'
        loss: 
          name: "CombinedLoss"
          params:
            alpha: 0.3
            ignore_index: 0
            
  Task05_Prostate:
    target_shape: [256, 256, 32]
    base_path: "datasets/Task05_Prostate/"
    images_subdir: "imagesTr"
    labels_subdir: "labelsTr"
    num_classes: 3

  Task06_Lung:
    target_shape: [512, 512, 128]
    base_path: "datasets/Task06_Lung/"
    images_subdir: "imagesTr"
    labels_subdir: "labelsTr"
    num_classes: 2

  Task07_Pancreas:
    target_shape: [256, 256, 64]
    base_path: "datasets/Task07_Pancreas/"
    images_subdir: "imagesTr"
    labels_subdir: "labelsTr"
    num_classes: 3

  Task08_HepaticVessel:
    target_shape: [512, 512, 128]
    base_path: "datasets/Task08_HepaticVessel/"
    images_subdir: "imagesTr"
    labels_subdir: "labelsTr"
    num_classes: 3

  Task09_Spleen:
    target_shape: [512, 512, 64]
    base_path: "datasets/Task09_Spleen/"
    images_subdir: "imagesTr"
    labels_subdir: "labelsTr"
    num_classes: 2

  Task10_Colon:
    target_shape: [256, 256, 128]
    base_path: "datasets/Task10_Colon/"
    images_subdir: "imagesTr"
    labels_subdir: "labelsTr"
    num_classes: 2
